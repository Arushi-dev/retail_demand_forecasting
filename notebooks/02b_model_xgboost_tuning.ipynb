{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ccde12-1d0d-4ba3-bc32-7788c85194b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load only 100k rows with relevant columns\n",
    "df = pd.read_parquet(\n",
    "    DATA_DIR / \"features_rossmann.parquet\",\n",
    "    columns=[\n",
    "        \"Sales\", \"Store\", \"DayOfWeek\", \"Promo\", \"SchoolHoliday\", \"StateHoliday\",\n",
    "        \"SalesLag1\", \"SalesLag7\", \"SalesMA7\", \"Year\", \"Month\", \"Week\", \"WeekOfYear\", \"IsWeekend\"\n",
    "    ]\n",
    ").iloc[:100_000]  # Load only the first 100,000 rows\n",
    "\n",
    "df = df.dropna(subset=[\"Sales\", \"SalesLag1\", \"SalesLag7\", \"SalesMA7\"])\n",
    "df[\"StateHoliday\"] = df[\"StateHoliday\"].astype(\"category\").cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24a6db1-e879-4411-a1ef-23c218acbc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize data types before dropna\n",
    "df[\"Store\"] = df[\"Store\"].astype(\"int32\")\n",
    "df[\"DayOfWeek\"] = df[\"DayOfWeek\"].astype(\"int8\")\n",
    "df[\"Promo\"] = df[\"Promo\"].astype(\"int8\")\n",
    "df[\"SchoolHoliday\"] = df[\"SchoolHoliday\"].astype(\"int8\")\n",
    "df[\"StateHoliday\"] = df[\"StateHoliday\"].astype(\"category\").cat.codes\n",
    "df[\"SalesLag1\"] = df[\"SalesLag1\"].astype(\"float32\")\n",
    "df[\"SalesLag7\"] = df[\"SalesLag7\"].astype(\"float32\")\n",
    "df[\"SalesMA7\"] = df[\"SalesMA7\"].astype(\"float32\")\n",
    "df[\"Year\"] = df[\"Year\"].astype(\"int16\")\n",
    "df[\"Month\"] = df[\"Month\"].astype(\"int8\")\n",
    "df[\"Week\"] = df[\"Week\"].astype(\"int8\")\n",
    "df[\"WeekOfYear\"] = df[\"WeekOfYear\"].astype(\"int8\")\n",
    "df[\"IsWeekend\"] = df[\"IsWeekend\"].astype(\"int8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3110a39d-de06-4cc0-816f-0ae449a10bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter to a few stores\n",
    "df = pd.read_parquet(DATA_DIR / \"features_rossmann.parquet\")\n",
    "df = df[df[\"Store\"].isin([1, 2, 3, 4, 5])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03b363c7-d94f-4165-98b2-b847f4880633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters: {'subsample': 1.0, 'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "Tuned Model RMSE: 881.90\n",
      "✅ Model and feature list saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# ✅ Step 1: Path Setup\n",
    "# -----------------------------\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\Arushi Sharma\\Documents\\retail_demand_forecasting\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODEL_DIR = PROJECT_ROOT / \"models\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# ✅ Step 2: Load Subset of Data\n",
    "# -----------------------------\n",
    "columns_to_use = [\n",
    "    \"Sales\", \"Store\", \"DayOfWeek\", \"Promo\", \"SchoolHoliday\", \"StateHoliday\",\n",
    "    \"SalesLag1\", \"SalesLag7\", \"SalesMA7\", \"Year\", \"Month\", \"WeekOfYear\", \"IsWeekend\"\n",
    "]\n",
    "df = pd.read_parquet(DATA_DIR / \"features_rossmann.parquet\", columns=columns_to_use).iloc[:100_000]\n",
    "\n",
    "# -----------------------------\n",
    "# ✅ Step 3: Preprocessing\n",
    "# -----------------------------\n",
    "df = df.dropna(subset=[\"Sales\", \"SalesLag1\", \"SalesLag7\", \"SalesMA7\"])  # Drop rows with missing values\n",
    "\n",
    "df[\"Store\"] = df[\"Store\"].astype(\"int32\")\n",
    "df[\"DayOfWeek\"] = df[\"DayOfWeek\"].astype(\"int8\")\n",
    "df[\"Promo\"] = df[\"Promo\"].astype(\"int8\")\n",
    "df[\"SchoolHoliday\"] = df[\"SchoolHoliday\"].astype(\"int8\")\n",
    "df[\"StateHoliday\"] = df[\"StateHoliday\"].astype(\"category\").cat.codes\n",
    "df[\"SalesLag1\"] = df[\"SalesLag1\"].astype(\"float32\")\n",
    "df[\"SalesLag7\"] = df[\"SalesLag7\"].astype(\"float32\")\n",
    "df[\"SalesMA7\"] = df[\"SalesMA7\"].astype(\"float32\")\n",
    "df[\"Year\"] = df[\"Year\"].astype(\"int16\")\n",
    "df[\"Month\"] = df[\"Month\"].astype(\"int8\")\n",
    "df[\"WeekOfYear\"] = df[\"WeekOfYear\"].astype(\"int8\")\n",
    "df[\"IsWeekend\"] = df[\"IsWeekend\"].astype(\"int8\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ Step 4: Train-Test Split (NO PRICE)\n",
    "# -----------------------------------------\n",
    "FEATURES = [\n",
    "    \"Store\", \"DayOfWeek\", \"Promo\", \"SchoolHoliday\", \"StateHoliday\",\n",
    "    \"SalesLag1\", \"SalesLag7\", \"SalesMA7\", \"Year\", \"Month\", \"WeekOfYear\", \"IsWeekend\"\n",
    "]\n",
    "TARGET = \"Sales\"\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ Step 5: Hyperparameter Tuning\n",
    "# -----------------------------------------\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ Step 6: Evaluate & Save\n",
    "# -----------------------------------------\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(f\"Tuned Model RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Save trained model and features\n",
    "joblib.dump(best_model, MODEL_DIR / \"xgb_best_model.pkl\")\n",
    "joblib.dump(FEATURES, MODEL_DIR / \"xgb_best_model_features.pkl\")\n",
    "\n",
    "print(\"✅ Model and feature list saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81478a05-fde3-4a5b-b3d9-7c1fea438627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 19972/20000 [04:26<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SHAP plot saved to: plots\\shap_xgb_best_model.png\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Optional: Set plot directory\n",
    "PLOT_DIR = Path(\"plots\")\n",
    "PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Create SHAP explainer for tuned XGBoost model\n",
    "explainer = shap.Explainer(best_model, X_train)\n",
    "\n",
    "# Calculate SHAP values for test data\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Plot and save summary plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test, show=False)  # Don't auto-show, so we can save\n",
    "plt.savefig(PLOT_DIR / \"shap_xgb_best_model.png\", bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"✅ SHAP plot saved to:\", PLOT_DIR / \"shap_xgb_best_model.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98e2a080-e237-457e-8227-16eb3d8b8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.bar(shap_values, show=False)\n",
    "plt.savefig(PLOT_DIR / \"shap_bar_xgb_best_model.png\", bbox_inches='tight', dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c7000a6-795f-4b5c-a9d2-535e9e7df9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 'AvgPrice' column not found in dataset.\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Price Simulation: Sales Forecast Under Price Changes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ Use the same features used for training\n",
    "expected_features = X_train.columns.tolist()\n",
    "\n",
    "# Ensure \"AvgPrice\" exists\n",
    "if \"AvgPrice\" not in X.columns:\n",
    "    print(\"❌ 'AvgPrice' column not found in dataset.\")\n",
    "else:\n",
    "    variants = {\n",
    "        \"Price -20%\": 0.80,\n",
    "        \"Price -10%\": 0.90,\n",
    "        \"Price +10%\": 1.10,\n",
    "        \"Price +20%\": 1.20,\n",
    "    }\n",
    "\n",
    "    baseline_preds = best_model.predict(X_test)\n",
    "\n",
    "    # Plot setup\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(baseline_preds[:100], label=\"Original\", linewidth=2)\n",
    "\n",
    "    for label, factor in variants.items():\n",
    "        X_sim = X_test.copy()\n",
    "        X_sim[\"AvgPrice\"] = X_sim[\"AvgPrice\"] * factor\n",
    "        y_sim = best_model.predict(X_sim)\n",
    "        plt.plot(y_sim[:100], label=label, linestyle=\"--\")\n",
    "\n",
    "    plt.title(\"🧪 Forecast Comparison: Price Simulation\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Predicted Sales\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "984b0e36-0add-4195-9bdc-b88390c340b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'variants' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m summary = []\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label, factor \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvariants\u001b[49m.items():\n\u001b[32m      6\u001b[39m     X_sim = X_test.copy()\n\u001b[32m      7\u001b[39m     X_sim[\u001b[33m\"\u001b[39m\u001b[33mAvgPrice\u001b[39m\u001b[33m\"\u001b[39m] = X_sim[\u001b[33m\"\u001b[39m\u001b[33mAvgPrice\u001b[39m\u001b[33m\"\u001b[39m] * factor\n",
      "\u001b[31mNameError\u001b[39m: name 'variants' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary = []\n",
    "\n",
    "for label, factor in variants.items():\n",
    "    X_sim = X_test.copy()\n",
    "    X_sim[\"AvgPrice\"] = X_sim[\"AvgPrice\"] * factor\n",
    "    y_sim = best_model.predict(X_sim)\n",
    "    \n",
    "    avg_delta = (y_sim - baseline_preds).mean()\n",
    "    summary.append({\"Scenario\": label, \"Avg Change in Sales\": avg_delta})\n",
    "\n",
    "pd.DataFrame(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f69e7-1f69-47a7-b0a2-728b6eee4729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
